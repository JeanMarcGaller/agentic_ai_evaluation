# Agentic AI Evaluation

This project implements a ü¶úüï∏Ô∏èLangGraph-based multi-agent evaluation system for answering complex questions using
LLMs, tools (e.g. Tavily Web Search), and self-reflection.

It compares the quality of initial and revised answers using 
LLM-powered evaluators.

---

## üîß Features

- üßû‚Äç‚ôÇÔ∏è **Responder** and üßû **Revisor** agents in a multi-agent LLM pipeline
- üîç **Tool-augmented reasoning** using Tavily Web Search when internal knowledge is insufficient
- ü™û **Self-reflective answering**, where agents critique and iteratively refine their responses
- ‚öñÔ∏è **LLM-as-a-judge** evaluating answers based on helpfulness, relevance, coherence, and conciseness
- ü§ù **Pairwise comparison** to determine which answer is better overall


---

## üóÇÔ∏è Project Structure

```text
agentic_ai_evaluation/
‚îÇ
‚îú‚îÄ‚îÄ main.py # Entry point: runs question-answer-evaluation pipeline
‚îú‚îÄ‚îÄ chains.py # Defines LLM agents (responder and revisor)
‚îú‚îÄ‚îÄ tool_executor.py # Wraps Tavily search tool for LangGraph
‚îú‚îÄ‚îÄ evaluator.py # Uses GPT-4 to evaluate answer quality
‚îú‚îÄ‚îÄ schemas.py # Defines structured outputs and tool schemas
‚îú‚îÄ‚îÄ load_data.py # Loads and samples HotpotQA questions
‚îî‚îÄ‚îÄ results.json # Output file containing evaluation results
```

---

## üõ†Ô∏è How It Works

1. üì• **Load questions** from a small sample of the HotpotQA dataset
2. üßû‚Äç‚ôÇÔ∏è **Responder agent** generates an initial answer using internal knowledge or Tavily web search
3. üßû **Revisor agent** critiques and improves the initial response using new context or tool results
4. ‚öñÔ∏è **LLM evaluator** scores both answers on multiple criteria and performs a pairwise comparison
5. üíæ **Save results** to `results.json` for analysis or reporting
---

## üß∞ Technologies Used

- üêç Python 3.11
- ü¶úüîó [LangChain](https://python.langchain.com)
- ü¶úüï∏Ô∏è [LangGraph](https://langgraph.readthedocs.io)
- ü¶úüî® [LangSmith](https://docs.smith.langchain.com/)
- üß†  [OpenAI API](https://openai.com/index/openai-api/)
- ü§ó [Hugging Face Datasets](https://huggingface.co/docs/datasets)
- üîç [Tavily](https://www.tavily.com)

## üöÄ Installation

1. Clone the repository:
```bash
git clone https://github.com/JeanMarcGaller/agentic_ai_evaluation.git
```

2. Install dependencies
```bash
pip install -r requirements.txt
```

3. Set up environment variables in a .env file and add your API keys:
```text
# OpenAI + Tavily keys
OPENAI_API_KEY=your-openai-key
TAVILY_API_KEY=your-tavily-key

# LangSmith Tracing configuration
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=agentic_ai_evaluation
LANGCHAIN_API_KEY=your-langsmith-api-key
```

4. Run the main script:
```bash
python main.py
```

This will:
- Sample 2 questions (can be changed via NUM_QUESTIONS)
- Run them through the agentic QA system 
- Save evaluations to results.json

---

## üß™ Customization Ideas
- Replace HotpotQA with NaturalQuestions or WebQuestions
- Add support for more tools (e.g. arXiv API, Wikipedia search)
- Test different LLMs
---

## üìö Citation

This project is inspired in part by the paper:

> Meng, Z., Dziri, N., Choudhury, M., Choi, Y., & Khashabi, D. (2023).  
> **Reflexion: Language Agents with Verbal Reinforcement Learning**.  
> arXiv: [2303.11366](https://arxiv.org/abs/2303.11366)

---

## üìÑ Attribution

This project includes components adapted from:


- [LangGraph Reflexion Tutorial](https://langchain-ai.github.io/langgraph/tutorials/reflexion/reflexion/) by the LangChain team,  
 used under the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).

- [Edan Marco](https://github.com/emarco177), used under the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).  
  Original codebase: [LangGraph Reflexion Agent](https://github.com/emarco177/langgraph-course)

---

## üìù License

This project is licensed under the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).

See the [LICENSE](./LICENSE) file for full license text and attribution details for third-party code reused or adapted in this project, including:

- LangGraph Reflexion Tutorial (LangChain Team)
- LangGraph Reflexion Agent (Edan Marco)



---

## üì¨ Contact

If you are interested in this work, have questions or recommendations, feel free to contact me via GitHub or email: 

Jean-Marc Galler

[jeanmarc.galler@students.fhnw.ch](mailto:jeanmarc.galler@students.fhnw.ch)
